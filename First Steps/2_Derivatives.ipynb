{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>  Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "from resources.utils.headers import *\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ y=x^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  $\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\mathrm{dy(x=2)}}{\\mathrm{dx}}=2(2)=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x ** 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative =  tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# derivatives\n",
    "y.backward()\n",
    "print('Derivative = ', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data =  tensor(2.)\n",
      "Grad_fn =  None\n",
      "Grad =  tensor(4.)\n",
      "is_leaf =  True\n",
      "requires_grad =  True\n"
     ]
    }
   ],
   "source": [
    "print('Data = ', x.data)\n",
    "print('Grad_fn = ', x.grad_fn)\n",
    "print('Grad = ', x.grad)\n",
    "print('is_leaf = ', x.is_leaf)\n",
    "print('requires_grad = ', x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data =  tensor(4.)\n",
      "Grad_fn =  <PowBackward0 object at 0x7f7d7b61fc50>\n",
      "Grad =  None\n",
      "is_leaf =  False\n",
      "requires_grad =  True\n"
     ]
    }
   ],
   "source": [
    "print('Data = ', y.data)\n",
    "print('Grad_fn = ', y.grad_fn)\n",
    "print('Grad = ', y.grad)\n",
    "print('is_leaf = ', y.is_leaf)\n",
    "print('requires_grad = ', y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $  y = x^2 + 2x + 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x+2$\n",
    "\n",
    "### $\\frac{\\mathrm{dy(x=2)}}{\\mathrm{dx}}=2(2)+2=6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x ** 2 + 2 * x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of  y = x^2 + 2x + 1 =  tensor(9., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Result of  y = x^2 + 2x + 1 = ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The derivative at x = 2: tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "print('The derivative at x = 2:', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### $ y = 2x^3+x $ at $x=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * x ** 3 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result  y = 2 ^ 3 + 1 =  tensor(3., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Result  y = 2 ^ 3 + 1 = ', y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative =  tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "print('Derivative = ', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQ(torch.autograd.Function):\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx,i):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        result=i**2\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        i, = ctx.saved_tensors\n",
    "        grad_output = 2*i\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = SQ.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SQBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.SQBackward object at 0x7f7d7b659d70>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.SQBackward object at 0x7f7d7b659d70>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: $f(u,v)=vu+u^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor(1.0, requires_grad = True)\n",
    "v = torch.tensor(2.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = u * v + u ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result =  tensor(3., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Result = ', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivatives with respect to u:  tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# derivatives\n",
    "f.backward()\n",
    "print('Partial derivatives with respect to u: ', u.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {u}}=v+2u$\n",
    "\n",
    "### $\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {u}}=2+2(1)=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivatives with respect to v:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# derivatives\n",
    "print('Partial derivatives with respect to v: ', v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {v}}=u$\n",
    "\n",
    "### $\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {v}}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: $ f=uv+(uv)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor(2.0, requires_grad = True)\n",
    "v = torch.tensor(1.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = u * v + (u * v) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of function =  tensor(6., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Result of function = ', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivatives with respect to u:  tensor(5.)\n",
      "Partial derivatives with respect to v:  tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "# derivatives\n",
    "print('Partial derivatives with respect to u: ', u.grad)\n",
    "print('Partial derivatives with respect to v: ', v.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
